{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13214087,"sourceType":"datasetVersion","datasetId":8375339}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:32:08.404022Z","iopub.execute_input":"2025-12-01T03:32:08.404378Z","iopub.status.idle":"2025-12-01T03:32:08.723199Z","shell.execute_reply.started":"2025-12-01T03:32:08.404354Z","shell.execute_reply":"2025-12-01T03:32:08.722570Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Celda 0 — Imports y configuración inicial - Verificación de archivos existentes","metadata":{}},{"cell_type":"code","source":"import os\n\nprint(\"Contenido de /kaggle/input:\")\nprint(os.listdir(\"/kaggle/input\"))\n\nprint(\"\\nContenido de /kaggle/input/nfl-big-data-bowl-2026-prediction:\")\nprint(os.listdir(\"/kaggle/input/nfl-big-data-bowl-2026-prediction\"))\n\nprint(\"\\nContenido de subcarpetas:\")\nfor folder in os.listdir(\"/kaggle/input/nfl-big-data-bowl-2026-prediction\"):\n    path = f\"/kaggle/input/nfl-big-data-bowl-2026-prediction/{folder}\"\n    if os.path.isdir(path):\n        print(f\"\\nCarpeta: {folder}\")\n        print(os.listdir(path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:32:08.724368Z","iopub.execute_input":"2025-12-01T03:32:08.724680Z","iopub.status.idle":"2025-12-01T03:32:08.731132Z","shell.execute_reply.started":"2025-12-01T03:32:08.724662Z","shell.execute_reply":"2025-12-01T03:32:08.730574Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Celda 01 - Lectura segura y emparejamiento de semanas\n\n✔ Garantiza que emparejamos correctamente.\n\n✔ No mezcla semanas incorrectamente.\n\n✔ Prepara el camino para unir input+output.","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport re\n\nDATA_DIR = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/train\"\n\nfiles = os.listdir(DATA_DIR)\ninput_files = sorted([f for f in files if f.startswith(\"input\")])\noutput_files = sorted([f for f in files if f.startswith(\"output\")])\n\nprint(\"INPUT FILES:\", len(input_files))\nprint(\"OUTPUT FILES:\", len(output_files))\n\n# Función para extraer número de semana\ndef get_week(fname):\n    m = re.search(r\"w(\\d+)\", fname)\n    return int(m.group(1))\n\n# Crear diccionarios por semana\ninputs_by_week = {get_week(f): f for f in input_files}\noutputs_by_week = {get_week(f): f for f in output_files}\n\n# Semanas existentes en ambos lados\nweeks = sorted(set(inputs_by_week.keys()) & set(outputs_by_week.keys()))\nprint(\"Semanas emparejadas:\", weeks)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:32:08.731717Z","iopub.execute_input":"2025-12-01T03:32:08.731941Z","iopub.status.idle":"2025-12-01T03:32:08.743005Z","shell.execute_reply.started":"2025-12-01T03:32:08.731911Z","shell.execute_reply":"2025-12-01T03:32:08.742295Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CELDA 2 — Crear los archivos train_pp (input + output) por semana\nEsta celda:\n\nLee el input y output de cada semana.\n\nLos une por claves estándar del tracking:\n\ngame_id\n\nplay_id\n\nnfl_id\n\nframe_id\n\nGuarda un archivo parquet por semana en /kaggle/working/train_pp.\n\nCon esto creamos el dataset necesario para el modelo profundo.","metadata":{}},{"cell_type":"code","source":"# ===============================================\n# CELDA 2: Crear train_pp por semana (input + output)\n# ===============================================\n\nimport os\nimport pandas as pd\nimport gc\n\nDATA_DIR = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/train\"\nTRAIN_PP = \"/kaggle/working/train_pp\"\nos.makedirs(TRAIN_PP, exist_ok=True)\n\nKEYS = [\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"]\n\nprint(\"Generando archivos train_pp...\\n\")\n\nfor week in weeks:\n    input_file = inputs_by_week[week]\n    output_file = outputs_by_week[week]\n\n    print(f\">> Semana {week:02d}\")\n    print(\"   Leyendo:\", input_file)\n    print(\"   Leyendo:\", output_file)\n\n    df_in = pd.read_csv(os.path.join(DATA_DIR, input_file))\n    df_out = pd.read_csv(os.path.join(DATA_DIR, output_file))\n\n    # Verificar columnas clave\n    for col in KEYS:\n        if col not in df_in.columns or col not in df_out.columns:\n            raise ValueError(f\"⚠ ERROR: La columna clave '{col}' no está en ambas tablas de la semana {week}.\")\n\n    # Merge seguro\n    df_merged = df_in.merge(df_out, on=KEYS, how=\"inner\", suffixes=(\"_in\", \"_out\"))\n\n    print(\"   Dimensiones input :\", df_in.shape)\n    print(\"   Dimensiones output:\", df_out.shape)\n    print(\"   Dimensiones merged:\", df_merged.shape)\n\n    # Guardar\n    out_path = os.path.join(TRAIN_PP, f\"train_w{week:02d}.parquet\")\n    df_merged.to_parquet(out_path, index=False)\n\n    del df_in, df_out, df_merged\n    gc.collect()\n\nprint(\"\\n✔ Todos los archivos train_pp creados correctamente.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:32:08.744506Z","iopub.execute_input":"2025-12-01T03:32:08.744800Z","iopub.status.idle":"2025-12-01T03:32:29.029666Z","shell.execute_reply.started":"2025-12-01T03:32:08.744783Z","shell.execute_reply":"2025-12-01T03:32:29.029026Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CELDA 3 — Unir todas las semanas en un solo archivo","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELDA 3: Unir semanas en train_full.parquet\n# ============================================\n\nimport os\nimport pandas as pd\nimport pyarrow as pa\nimport pyarrow.parquet as pq\nimport gc\n\nTRAIN_PP = \"/kaggle/working/train_pp\"\ntrain_full_path = \"/kaggle/working/train_full.parquet\"\n\nfiles = sorted([f for f in os.listdir(TRAIN_PP) if f.endswith(\".parquet\")])\nprint(\"Archivos detectados:\", len(files))\n\nwriter = None\n\nfor i, fname in enumerate(files):\n    path = os.path.join(TRAIN_PP, fname)\n    print(f\">> Añadiendo {fname} ({i+1}/{len(files)})\")\n\n    df = pd.read_parquet(path)\n    table = pa.Table.from_pandas(df, preserve_index=False)\n\n    if writer is None:\n        writer = pq.ParquetWriter(train_full_path, table.schema)\n\n    writer.write_table(table)\n\n    del df, table\n    gc.collect()\n\nif writer is not None:\n    writer.close()\n\nprint(\"\\n✔ train_full.parquet creado correctamente.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:32:29.030319Z","iopub.execute_input":"2025-12-01T03:32:29.030505Z","iopub.status.idle":"2025-12-01T03:32:30.827966Z","shell.execute_reply.started":"2025-12-01T03:32:29.030490Z","shell.execute_reply":"2025-12-01T03:32:30.827355Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CELDA 4 — EDA PROFUNDO (Exploratory Data Analysis)\n\nEsta celda:\n\nPermite describir las variables de entrada\n\nAnaliza el dataset de forma científica\n\nPermite dar la justificación objetiva para usar modelos secuenciales (RNN/CNN/Transformers)","metadata":{}},{"cell_type":"code","source":"# ===============================================\n# CELDA 4: ANÁLISIS EXPLORATORIO DEL DATASET\n# ===============================================\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_parquet(\"/kaggle/working/train_full.parquet\")\n\nprint(\"Shape final del dataset:\", df.shape)\nprint(\"\\nColumnas disponibles:\")\nprint(df.columns.tolist())\n\n# -----------------------------------------\n# 1. Valores faltantes\n# -----------------------------------------\nmissing = df.isna().mean().sort_values(ascending=False)\n\nplt.figure(figsize=(8,6))\nmissing.head(20).plot.barh(color=\"steelblue\")\nplt.title(\"Proporción de valores faltantes por columna (Top 20)\")\nplt.xlabel(\"Proporción de NA\")\nplt.ylabel(\"Variable\")\nplt.show()\n\nprint(\"\\nTabla completa de valores faltantes:\")\nprint(missing)\n\n# -----------------------------------------\n# 2. Estadísticas descriptivas\n# -----------------------------------------\nprint(\"\\nEstadísticas descriptivas para columnas numéricas:\")\nprint(df.describe())\n\n# -----------------------------------------\n# 3. Distribución de variables de movimiento\n# -----------------------------------------\nfig, axes = plt.subplots(2, 2, figsize=(12,8))\n\naxes[0,0].hist(df[\"s\"], bins=50, color=\"royalblue\")\naxes[0,0].set_title(\"Distribución de velocidad (s)\")\n\naxes[0,1].hist(df[\"a\"], bins=50, color=\"firebrick\")\naxes[0,1].set_title(\"Distribución de aceleración (a)\")\n\naxes[1,0].hist(df[\"o\"], bins=50, color=\"darkgreen\")\naxes[1,0].set_title(\"Distribución de orientación (o)\")\n\naxes[1,1].hist(df[\"dir\"], bins=50, color=\"purple\")\naxes[1,1].set_title(\"Distribución de dirección (dir)\")\n\nplt.tight_layout()\nplt.show()\n\n# -----------------------------------------\n# 4. Distribución de posiciones en el campo\n# -----------------------------------------\nplt.figure(figsize=(7,6))\nsns.kdeplot(x=df[\"x_in\"], y=df[\"y_in\"], fill=True, cmap=\"viridis\", thresh=0.05)\nplt.title(\"Mapa de densidad del campo (x_in vs y_in)\")\nplt.xlabel(\"x_in\")\nplt.ylabel(\"y_in\")\nplt.show()\n\n# -----------------------------------------\n# 5. Variables objetivo: x_out, y_out\n# -----------------------------------------\nfig, ax = plt.subplots(1, 2, figsize=(12,5))\n\nax[0].hist(df[\"x_out\"], bins=50, color=\"orange\")\nax[0].set_title(\"Distribución de x_out (target)\")\n\nax[1].hist(df[\"y_out\"], bins=50, color=\"teal\")\nax[1].set_title(\"Distribución de y_out (target)\")\n\nplt.show()\n\n# -----------------------------------------\n# 6. Frame_id: estructura temporal del tracking\n# -----------------------------------------\nplt.figure(figsize=(7,4))\ndf[\"frame_id\"].hist(bins=60, color=\"gray\")\nplt.title(\"Distribución global de frame_id\")\nplt.xlabel(\"frame_id (tiempo discreto)\")\nplt.ylabel(\"Frecuencia\")\nplt.show()\n\nprint(\"\\nEDA completo generado correctamente.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:32:30.828618Z","iopub.execute_input":"2025-12-01T03:32:30.828816Z","iopub.status.idle":"2025-12-01T03:38:17.377706Z","shell.execute_reply.started":"2025-12-01T03:32:30.828801Z","shell.execute_reply":"2025-12-01T03:38:17.376960Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CELDA 5 — Limpieza, ingeniería de características y preparación final del dataset\n\n### Resumen: Preprocesamiento y Feature Engineering (Celda 5)\n\nEsta etapa garantiza la **integridad de los datos** y adapta las variables para la arquitectura del Transformer:\n\n1.  **Seguridad (Data Safety):** Se crea una `copy()` del dataframe para preservar la fuente original intacta.\n2.  **Conversión de Unidades:**\n    * **Estatura:** Transformación de formato texto (pies-pulgadas) a escala numérica continua (pulgadas) para consistencia matemática.\n    * **Temporalidad:** Conversión de *fecha de nacimiento* a *edad*, maximizando la carga informativa.\n3.  **Tratamiento de Señales Cíclicas (Ángulos):**\n    * Las variables de orientación (`dir`, `o`) se descomponen en sus componentes ortogonales: $\\sin(\\theta)$ y $\\cos(\\theta)$.\n    * **Justificación:** Elimina la discontinuidad numérica entre $0^\\circ$ y $360^\\circ$, fundamental para que el modelo interprete correctamente la dirección espacial.\n4.  **Codificación Categórica (LabelEncoder):**\n    * Se transforman categorías (jugadores, posiciones) a índices enteros.\n    * **Motivo:** Necesario para alimentar las capas de **Embeddings** (vectores densos) del Transformer, evitando la explosión dimensional del *One-Hot Encoding*.\n5.  **Normalización (`StandardScaler`):**\n    * Estandarización de variables numéricas ($z = \\frac{x - \\mu}{\\sigma}$).\n    * **Crítico:** Los mecanismos de atención (*dot products*) requieren escalas balanceadas para evitar inestabilidad en los gradientes y asegurar una convergencia eficiente.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n# ============================================================\n# 1. COPIA DE SEGURIDAD\n# ============================================================\ndf_clean = df.copy()\n\nprint(\"Shape inicial:\", df_clean.shape)\n\n# ============================================================\n# 2. PROCESAMIENTO DE ALTURA: Convertir '6-2' → 74 pulgadas\n# ============================================================\ndef convert_height(h):\n    try:\n        feet, inches = h.split(\"-\")\n        return int(feet) * 12 + int(inches)\n    except:\n        return np.nan\n\ndf_clean[\"player_height_inches\"] = df_clean[\"player_height\"].apply(convert_height)\n\n# ============================================================\n# 3. CONVERSIÓN DE FECHA A EDAD\n# ============================================================\ndf_clean[\"player_birth_date\"] = pd.to_datetime(df_clean[\"player_birth_date\"], errors=\"coerce\")\ndf_clean[\"player_age\"] = (pd.Timestamp(\"2024-01-01\") - df_clean[\"player_birth_date\"]).dt.days / 365.25\n\n# ============================================================\n# 4. TRATAMIENTO DE VARIABLES ANGULARES (dir, o)\n#    Convertir a seno y coseno para evitar discontinuidades\n# ============================================================\ndf_clean[\"dir_rad\"] = np.deg2rad(df_clean[\"dir\"])\ndf_clean[\"o_rad\"] = np.deg2rad(df_clean[\"o\"])\n\ndf_clean[\"dir_sin\"] = np.sin(df_clean[\"dir_rad\"])\ndf_clean[\"dir_cos\"] = np.cos(df_clean[\"dir_rad\"])\n\ndf_clean[\"o_sin\"] = np.sin(df_clean[\"o_rad\"])\ndf_clean[\"o_cos\"] = np.cos(df_clean[\"o_rad\"])\n\n# ============================================================\n# 5. ELIMINAR COLUMNAS QUE YA NO SE NECESITAN\n# ============================================================\ndf_clean.drop(columns=[\"player_height\", \"dir_rad\", \"o_rad\"], inplace=True)\n\n# ============================================================\n# 6. CODIFICACIÓN CATEGÓRICA (Label Encoding)\n#    Para usarlas luego como embeddings en el modelo\n# ============================================================\ncategorical_cols = [\n    \"player_position\",\n    \"player_side\",\n    \"player_role\",\n    \"play_direction\",\n    \"player_name\"\n]\n\nlabel_encoders = {}\nfor col in categorical_cols:\n    le = LabelEncoder()\n    df_clean[col] = le.fit_transform(df_clean[col].astype(str))\n    label_encoders[col] = le\n\n# ============================================================\n# 7. NORMALIZACIÓN DE VARIABLES NUMÉRICAS\n# ============================================================\nnum_cols = [\n    \"x_in\", \"y_in\", \"s\", \"a\",\n    \"absolute_yardline_number\",\n    \"player_height_inches\", \"player_weight\", \"player_age\",\n    \"dir_sin\", \"dir_cos\", \"o_sin\", \"o_cos\"\n]\n\nscaler = StandardScaler()\ndf_clean[num_cols] = scaler.fit_transform(df_clean[num_cols])\n\n# ============================================================\n# 8. RESULTADOS\n# ============================================================\nprint(\"\\nShape final:\", df_clean.shape)\nprint(\"\\nColumnas finales:\")\nprint(df_clean.columns.tolist())\nprint(\"\\nEjemplo de 5 filas:\\n\", df_clean.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:38:17.378628Z","iopub.execute_input":"2025-12-01T03:38:17.379008Z","iopub.status.idle":"2025-12-01T03:38:18.583255Z","shell.execute_reply.started":"2025-12-01T03:38:17.378983Z","shell.execute_reply":"2025-12-01T03:38:18.582592Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Correcciones.\n\n### Depuración y Selección de Variables (Feature Selection)\n\nEl siguiente análisis justifica las acciones correctivas aplicadas al conjunto de datos para garantizar la validez científica del modelo y evitar errores metodológicos comunes:\n\n1.  **Prevención de Fuga de Información (Data Leakage):**\n    * Se excluyen las variables `ball_land_x` y `ball_land_y`. Dado que estas métricas representan el estado final del evento (coordenadas de aterrizaje), su inclusión en el vector de entrada violaría el principio de causalidad, permitiendo al modelo inferir el resultado trivialmente en lugar de aprender la dinámica del sistema. Esto asegura métricas de evaluación realistas y no artificialmente optimistas.\n\n2.  **Mitigación de Sobreajuste por Identidad:**\n    * Se elimina la variable `player_name`. Al tratarse de un identificador de alta cardinalidad, su presencia induce al modelo a memorizar comportamientos de individuos específicos en lugar de generalizar patrones físicos universales. En un contexto riguroso, se priorizan las características atléticas sobre las etiquetas nominales.\n\n3.  **Reducción de Redundancia y Ruido:**\n    * Se descarta `player_birth_date` en favor de la variable derivada `player_age`. Mantener la fecha cruda introduce ruido de formato y duplicidad dimensional sin aportar valor predictivo adicional sobre la edad calculada.\n\n4.  **Codificación y Reproducibilidad:**\n    * La conversión de variables categóricas mediante `LabelEncoder` se valida como el método adecuado para alimentar capas de *embeddings*. Se enfatiza la necesidad de persistencia (guardado) de estos objetos codificadores para garantizar la correcta transformación de los datos de prueba y la reproducibilidad futura del sistema.\n\n5.  **Estabilidad Numérica del Entrenamiento:**\n    * El escalado de variables numéricas es un requisito mandatorio. Arquitecturas basadas en gradientes, como Transformers o MLPs, requieren entradas normalizadas para evitar la saturación de neuronas y asegurar una convergencia estable y eficiente.\n\n6.  **Coherencia del Conjunto de Entrenamiento:**\n    * Se aplica un filtro estricto sobre `player_to_predict == True`. Entrenar con instancias que carecen de una variable objetivo definida o válida introduce ruido y distorsiona la función de pérdida. El modelo debe aprender exclusivamente de muestras con una relación entrada-salida verificable.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# ============================\n# CELDA CORRECCIÓN: LIMPIEZA FINAL\n# ============================\nimport os\nimport pickle\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\ndf2 = df_clean.copy()  # partir de tu df_clean actual\n\n# 1) Eliminar columnas que pueden originar leakage o que no son features útiles\ncols_drop = [\"ball_land_x\", \"ball_land_y\", \"player_name\", \"player_birth_date\"]\nfor c in cols_drop:\n    if c in df2.columns:\n        df2.drop(columns=[c], inplace=True)\n\n# 2) Asegurarnos que 'player_to_predict' es booleana y filtrar si corresponde\nif \"player_to_predict\" in df2.columns:\n    # Si tu objetivo es predecir solo para el sujeto marcado True, filtra:\n    # (Sino omite esta línea. Revisa si tienes que usar todas las filas.)\n    df2 = df2[df2[\"player_to_predict\"]==True].reset_index(drop=True)\n\n# 3) Columnas categóricas a usar como índices para embeddings (NO incluir player_name)\ncategorical_cols = []\nfor c in [\"player_position\", \"player_side\", \"player_role\", \"play_direction\"]:\n    if c in df2.columns:\n        categorical_cols.append(c)\n\n# Aplicar LabelEncoder y guardar encoders\nlabel_encoders = {}\nfor col in categorical_cols:\n    le = LabelEncoder()\n    df2[col] = le.fit_transform(df2[col].astype(str))\n    label_encoders[col] = le\n\n# Guardar los encoders para uso posterior\nos.makedirs(\"/kaggle/working/encoders\", exist_ok=True)\nwith open(\"/kaggle/working/encoders/label_encoders.pkl\", \"wb\") as f:\n    pickle.dump(label_encoders, f)\n\n# 4) Seleccionar columnas numéricas a escalar (excluir targets x_out, y_out)\nnum_cols = [\n    \"x_in\", \"y_in\", \"s\", \"a\",\n    \"absolute_yardline_number\",\n    \"player_height_inches\", \"player_weight\", \"player_age\",\n    \"dir_sin\", \"dir_cos\", \"o_sin\", \"o_cos\"\n]\n# Filtrar las que realmente existan\nnum_cols = [c for c in num_cols if c in df2.columns]\n\nscaler = StandardScaler()\ndf2[num_cols] = scaler.fit_transform(df2[num_cols])\n\n# Guardar scaler\nwith open(\"/kaggle/working/encoders/num_scaler.pkl\", \"wb\") as f:\n    pickle.dump(scaler, f)\n\n# 5) Eliminar columnas que ya no usarás (opcionales y seguras)\n#    (por ejemplo: player_to_predict si ya filtraste, o nfl_id si no la usarás)\n# Aqui dejo nfl_id porque puede ser útil si vas a hacer embeddings de jugadores; si no, descomenta la línea.\n# df2.drop(columns=[\"nfl_id\"], inplace=True)\n\n# 6) Resumen final\nprint(\"Shape final después de correcciones:\", df2.shape)\nprint(\"Columnas finales (preview):\", df2.columns.tolist())\n\n# Guardar parquet corregido para las siguientes celdas\nout_path = \"/kaggle/working/train_clean.parquet\"\ndf2.to_parquet(out_path, index=False)\nprint(\"Guardado:\", out_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:38:18.583997Z","iopub.execute_input":"2025-12-01T03:38:18.584264Z","iopub.status.idle":"2025-12-01T03:38:20.235807Z","shell.execute_reply.started":"2025-12-01T03:38:18.584239Z","shell.execute_reply":"2025-12-01T03:38:20.235116Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Celda 6 - cargar dataset limpio.\nEsta celda construye el corazón del modelo completo:\n\n✔️ 1. Positional Encoding\n\nComo en cualquier Transformer:\n\nAñade una señal sen/cos para indicar posición temporal.\n\nSin ella, el modelo no sabría cuál frame es primero o último.\n\n✔️ 2. Linear Input Projection\n\nLa entrada tiene ~14–16 features.\nEl Transformer funciona mejor en espacios más grandes:\n\n→ Lo ampliamos a d_model = 128.\n\n✔️ 3. Transformer Encoder\n\nCon:\n\natención multi-cabeza\n\nfeedforward interno\n\ndropout\n\nmáscara de padding\n\nEsto permite aprender patrones temporales:\n\ncambios de velocidad\n\ndirección\n\nmovimiento lateral\n\ndesplazamiento continuo en el tiempo\n\n✔️ 4. Output Head\n\nToma cada frame del encoding y predice:\n\nx_out\n\ny_out\n\n✔️ 5. Máscara de padding\n\nEvita que secuencias cortas contaminen el batch.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport math\n\n# ============================================================\n# Cargar dataset limpio solo para obtener input_dim\n# ============================================================\ndf_tmp = pd.read_parquet(\"/kaggle/working/train_clean.parquet\")\n\n# features de entrada (sin targets)\nINPUT_FEATURES = [\n    \"x_in\",\"y_in\",\"s\",\"a\",\n    \"dir_sin\",\"dir_cos\",\n    \"o_sin\",\"o_cos\",\n    \"play_direction\",\n    \"absolute_yardline_number\",\n    \"player_height_inches\",\n    \"player_weight\",\n    \"player_age\"\n]\n\ninput_dim = len(INPUT_FEATURES)\nprint(\"input_dim =\", input_dim)\n\n\n# ============================================================\n# POSITIONAL ENCODING\n# ============================================================\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len).float().unsqueeze(1)\n\n        div_term = torch.exp(\n            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n        )\n\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n\n        self.register_buffer(\"pe\", pe.unsqueeze(0))\n\n    def forward(self, x):\n        seq_len = x.size(1)\n        return x + self.pe[:, :seq_len, :]\n\n\n# ============================================================\n# TRANSFORMER MODEL\n# ============================================================\nclass TransformerTrajectoryModel(nn.Module):\n    def __init__(self, input_dim, d_model=128, nhead=4,\n                 num_layers=3, dim_feedforward=256,\n                 dropout=0.1, output_dim=2):\n\n        super().__init__()\n        self.input_proj = nn.Linear(input_dim, d_model)\n        self.pos_encoder = PositionalEncoding(d_model)\n\n        layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(layer, num_layers=num_layers)\n\n        self.output_head = nn.Sequential(\n            nn.Linear(d_model, d_model // 2),\n            nn.ReLU(),\n            nn.Linear(d_model // 2, output_dim)\n        )\n\n        self._init_weights()\n\n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, x, padding_mask=None):\n        x = self.input_proj(x)\n        x = self.pos_encoder(x)\n\n        if padding_mask is not None:\n            src_key_padding_mask = (padding_mask == 0)\n        else:\n            src_key_padding_mask = None\n\n        enc = self.encoder(x, src_key_padding_mask=src_key_padding_mask)\n        out = self.output_head(enc)\n        return out\n\n\n# ============================================================\n# TEST DEL MODELO (sin requerir que exista batch_x)\n# ============================================================\nprint(\"Generando batch temporal de prueba...\")\nbatch_x = torch.randn(4, 20, input_dim)\nbatch_mask = torch.ones(4, 20)\n\nmodel = TransformerTrajectoryModel(input_dim=input_dim)\npreds = model(batch_x, padding_mask=batch_mask)\n\nprint(\"Pred shape =\", preds.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:38:20.236530Z","iopub.execute_input":"2025-12-01T03:38:20.236769Z","iopub.status.idle":"2025-12-01T03:38:24.400271Z","shell.execute_reply.started":"2025-12-01T03:38:20.236751Z","shell.execute_reply":"2025-12-01T03:38:24.399499Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"# Celda 7 - construcción de secuencias, DataLoaders y split por grupo\n##  Preparación de Datos Secuenciales para Modelo Transformer\n\nEste proceso se centra en transformar datos de seguimiento (tracking data) en secuencias estandarizadas, adecuadas para el entrenamiento de un modelo de aprendizaje profundo que predice coordenadas **frame-a-frame**.\n\n| Sección | Concepto | Descripción Detallada |\n| :---: | :---: | :--- |\n| **1** | **Selección de Entradas y Objetivos** | **`INPUT_FEATURES`** corresponde exactamente a las **columnas normalizadas y pre-procesadas** (ej. $v_x, v_y, \\text{distancia a la pelota}$, etc.). **`TARGET_COLS = [\"x_out\", \"y_out\"]`** son las coordenadas de salida (posiciones) que el modelo debe predecir en cada paso de tiempo (frame). |\n| **2** | **Agrupamiento para Crear Secuencias** | Se agrupa la información utilizando la tupla **`(game_id, play_id, nfl_id)`**. Esto es crucial porque cada secuencia debe encapsular el movimiento **completo de un jugador específico** dentro de una jugada única. Luego, se ordena estrictamente por **`frame_id`** para mantener la **cronología temporal** de la señal. |\n| **3** | **Filtrado por Longitud Mínima** | Se impone un umbral **`MIN_SEQ_LEN = 2`**. Este filtro es una medida de calidad para garantizar que cada secuencia resultante contenga al menos un par **entrada $\\rightarrow$ salida** significativo. Secuencias de longitud 1 se consideran **triviales** y se descartan por no ofrecer suficiente contexto para el entrenamiento secuencial. |\n| **4** | **Split por GroupKFold (Estrategia Anti-Leakage)** | Se utiliza **`GroupKFold`** con **`play_id`** como variable de agrupación. Esta es una práctica fundamental para evitar el **data leakage** (fuga de información), asegurando que una misma jugada **entera** nunca aparezca simultáneamente en los conjuntos de entrenamiento y validación. Se seleccionan **5 folds** y se usa el primer *split* para obtener el conjunto de validación. |\n| **5** | **Dataset y `collate_fn` (Padding y Máscara)** | La clase **`NFLSeqDataset`** produce secuencias de **longitud variable** ($T_i, F$). La función **`collate_fn`** es esencial: realiza el **padding** (relleno) de las secuencias al largo máximo del *batch* ($T_{\\text{max}}$) y, crucialmente, genera una **máscara binaria** (**`mask`**) donde $1.0$ indica un *token* (frame) **válido** y $0.0$ indica *padding*. Esta máscara se convierte y se utiliza en el Transformer como **`src_key_padding_mask`** (donde $0 \\rightarrow \\text{válido}, 1 \\rightarrow \\text{pad}$). |\n| **6** | **DataLoader y `batch_size`** | Se establece **`BATCH_SIZE = 32`**, un valor que apunta a un buen equilibrio entre velocidad de entrenamiento y **estabilidad del gradiente**. Se utilizan **`num_workers=2`** y **`pin_memory=True`** para optimizar la transferencia de datos a la GPU (si aplica). El uso de **`shuffle=True`** en el *train set* es la manera tradicional de garantizar la mezcla de datos en cada *epoch*. |\n| **7** | **Salidas Verificadas (Dimensionalidad del Batch)** | Los tensores resultantes del `DataLoader` cumplen con las siguientes formas (donde $B=32$ y $T_{\\text{max}}$ es la longitud máxima del batch): |\n| | **`batch_x` (Entradas)** | Forma: $(32, T_{\\text{max}}, 13)$ |\n| | **`batch_y` (Objetivos)** | Forma: $(32, T_{\\text{max}}, 2)$ |\n| | **`batch_mask` (Máscara)** | Forma: $(32, T_{\\text{max}})$ (Valores: $1.0$ para válido, $0.0$ para *padding*) |\n| | **`lengths` (Longitudes Reales)** | Vector de longitudes reales ($T_i$) para cada secuencia del batch. |","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# CELDA 7 — ConstruCCIÓN DE SECUENCIAS (frame-to-frame) y DATALOADERS\n# ============================================================\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom sklearn.model_selection import GroupKFold\n\n# ============================================================\n# 1) Cargar dataset limpio\n# ============================================================\ndf = pd.read_parquet(\"/kaggle/working/train_clean.parquet\")\nprint(\"df shape:\", df.shape)\n\n# ============================================================\n# 2) Construir secuencias por (game_id, play_id, nfl_id)\n# ============================================================\ngroup_cols = [\"game_id\", \"play_id\", \"nfl_id\"]\n\n# Orden por frame para mantener secuencias correctas\ndf = df.sort_values(group_cols + [\"frame_id\"])\n\n# Variables de entrada\ninput_features = [\"x_in\", \"y_in\", \"s\", \"a\", \"dir\", \"o\",\n                  \"player_height_inches\", \"player_age\",\n                  \"dir_sin\", \"dir_cos\", \"o_sin\", \"o_cos\",\n                  \"absolute_yardline_number\"]\n\n# Variables de salida\noutput_features = [\"x_out\", \"y_out\"]\n\nX_seqs, Y_seqs, group_ids = [], [], []\n\nprint(\"Construyendo secuencias:\")\nfor (g, p, n), group_df in tqdm(df.groupby(group_cols), total=df[group_cols].drop_duplicates().shape[0]):\n\n    x_seq = group_df[input_features].values.astype(np.float32)\n    y_seq = group_df[output_features].values.astype(np.float32)\n\n    X_seqs.append(torch.tensor(x_seq))\n    Y_seqs.append(torch.tensor(y_seq))\n\n    # group_id = play_id → asegura que un mismo play no aparezca en train y val\n    group_ids.append(p)\n\nprint(\"Total secuencias creadas:\", len(X_seqs))\n\nseq_lengths = [len(x) for x in X_seqs]\nprint(\"Longitud media de secuencia:\", np.mean(seq_lengths), \"mediana:\", np.median(seq_lengths))\n\n# ============================================================\n# 3) Padding y creación del Dataset\n# ============================================================\n\nclass SequenceDataset(Dataset):\n    def __init__(self, X_list, Y_list, max_len=20):\n        self.X_list = X_list\n        self.Y_list = Y_list\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.X_list)\n\n    def __getitem__(self, idx):\n        x = self.X_list[idx]\n        y = self.Y_list[idx]\n\n        L = len(x)\n        pad_len = self.max_len - L\n\n        if pad_len > 0:\n            x_pad = torch.cat([x, torch.zeros(pad_len, x.shape[1])], dim=0)\n            y_pad = torch.cat([y, torch.zeros(pad_len, y.shape[1])], dim=0)\n            mask = torch.cat([torch.ones(L), torch.zeros(pad_len)])\n        else:\n            x_pad = x[:self.max_len]\n            y_pad = y[:self.max_len]\n            mask = torch.ones(self.max_len)\n\n        return x_pad, y_pad, mask\n\nMAX_LEN = 20\ndataset_all = SequenceDataset(X_seqs, Y_seqs, max_len=MAX_LEN)\n\n# ============================================================\n# 4) Split train/val por GroupKFold\n# ============================================================\n\ngkf = GroupKFold(n_splits=5)\nindices = np.arange(len(X_seqs))\n\ntrain_idx, val_idx = None, None\n\n# X = indices, y = None, groups = group_ids\nfor train_index, val_index in gkf.split(indices, groups=group_ids):\n    train_idx, val_idx = train_index, val_index\n    break\n\nprint(\"Train sequences:\", len(train_idx), \"Val sequences:\", len(val_idx))\n\n# ============================================================\n# 5) Crear DataLoaders (BATCH SIZE = 32)\n# ============================================================\n\nbatch_size = 32\n\ntrain_subset = torch.utils.data.Subset(dataset_all, train_idx)\nval_subset   = torch.utils.data.Subset(dataset_all, val_idx)\n\ntrain_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\nval_loader   = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n\nprint(\"DataLoaders creados correctamente.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:38:24.402599Z","iopub.execute_input":"2025-12-01T03:38:24.402985Z","iopub.status.idle":"2025-12-01T03:38:55.589479Z","shell.execute_reply.started":"2025-12-01T03:38:24.402967Z","shell.execute_reply":"2025-12-01T03:38:55.588591Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CELDA 8 — ENTRENAMIENTO (Transformer, AdamW, MAE, EarlyStopping, Checkpoint)\n\n**1) Device**\n\nSe detecta CUDA y se usa DEVICE. En Kaggle, si añadiste GPU, será GPU; si no, CPU (más lento).\n\n**2) Modelo**\n\nReutiliza la clase TransformerTrajectoryModel que ya probaste y validaste (input_dim=13). Mantengo d_model=128, 3 capas, 4 cabezas.\n\n**3) Optimizer AdamW**\n\nAdamW corrige el decaimiento de peso aplicado directamente a los parámetros (weight decay) y suele generalizar mejor.\n\n**4) Scheduler ReduceLROnPlateau**\n\nSi el val_loss no mejora, baja LR a la mitad (factor 0.5) tras patience=3. Esto estabiliza ajustes finos.\n\n**5) Loss**\n\nUsamos MAE (L1). Implementación: sumamos errores solo donde mask==1, dividimos por número real de elementos válidos. De este modo evitamos que el padding contamine la métrica.\n\n**6) Masked computation**\n\nmask es (B,T) con 1.0=valido, 0.0=pad.\n\nExpandimos a (B,T,1) para combinar con pred y target.\n\nEvitamos división por cero con +1e-12.\n\n**7) Gradient clipping**\n\nCortamos norma gradiente a 1.0 para evitar saltos. Muy útil en Transformers.\n\n**8) Checkpoint**\n\nGuardamos el mejor modelo (según val_mae) en MODEL_PATH. También guardamos el optimizador en ese checkpoint.\n\n**9) Early stopping**\n\nPATIENCE=6 epochs sin mejora → interrumpe. Evita sobreentrenar.\n\n**10) Historial**\n\nSe guarda history con métricas que puedes graficar luego (train/val MAE vs epoch).","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# CELDA 8 — ENTRENAMIENTO\n# ============================================================\nimport os\nimport time\nimport copy\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import AdamW\nfrom tqdm.auto import tqdm\nimport numpy as np\n\n# Parámteros de entrenamiento\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nEPOCHS = 30\nLR = 1e-4\nWEIGHT_DECAY = 1e-5\nPATIENCE = 6                 # early stopping patience\nGRAD_CLIP = 1.0\nMODEL_PATH = \"/kaggle/working/best_transformer_model.pth\"\n\nprint(\"DEVICE:\", DEVICE)\n\n# ---------------------------------------------------------------------\n# Reutilizamos la clase TransformerTrajectoryModel ya definida en la celda 6.\n# Asegúrate de que la definición está en memoria; si no, vuelve a correr la celda 6.\n# ---------------------------------------------------------------------\nmodel = TransformerTrajectoryModel(input_dim=input_dim, d_model=128, nhead=4, num_layers=3, dim_feedforward=256, dropout=0.1, output_dim=2)\nmodel.to(DEVICE)\n\n# Optimizer + scheduler\noptimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n\n# Loss: podremos calcular MAE manualmente con mask\n# pero podemos use nn.L1Loss(reduction='sum') and divide by valid tokens\ncriterion = nn.L1Loss(reduction='sum')\n\n# Early stopping bookkeeping\nbest_val_mae = float(\"inf\")\nbest_model_wts = copy.deepcopy(model.state_dict())\nepochs_no_improve = 0\nhistory = {\"train_mae\": [], \"val_mae\": [], \"train_loss\": [], \"val_loss\": [], \"lr\": []}\n\n# Helper to compute masked MAE\ndef masked_mae(preds, targets, mask):\n    \"\"\"\n    preds, targets: (B, T, 2)\n    mask: (B, T) with 1.0 valid, 0.0 padding\n    returns: mae scalar\n    \"\"\"\n    # Expand mask to match last dim\n    mask3 = mask.unsqueeze(-1)  # (B, T, 1)\n    diff = torch.abs(preds - targets) * mask3  # (B, T, 2)\n    sum_diff = diff.sum()\n    valid = mask3.sum()\n    if valid.item() == 0:\n        return torch.tensor(0.0, device=preds.device), 0.0\n    mae = (sum_diff / valid).item()  # mean absolute error per coordinate\n    return torch.tensor(mae, device=preds.device), valid.item()\n\n# Training loop\nfor epoch in range(1, EPOCHS + 1):\n    t0 = time.time()\n    model.train()\n    running_loss = 0.0\n    running_mae_sum = 0.0\n    running_tokens = 0.0\n\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} — train\", leave=False)\n    for batch in pbar:\n        # batch: x_pad, y_pad, mask (SequenceDataset returns these)\n        x_batch, y_batch, mask_batch = batch  # shapes: (B, T, F), (B, T, 2), (B, T)\n        x_batch = x_batch.to(DEVICE)\n        y_batch = y_batch.to(DEVICE)\n        mask_batch = mask_batch.to(DEVICE)\n\n        optimizer.zero_grad()\n        preds = model(x_batch, padding_mask=mask_batch)  # (B, T, 2)\n\n        # compute loss only on valid tokens\n        # use criterion with reduction=sum then divide by valid tokens\n        mask3 = mask_batch.unsqueeze(-1)\n        loss_sum = torch.abs(preds - y_batch) * mask3\n        loss_sum = loss_sum.sum()  # scalar sum over batch and dims\n        valid_tokens = mask3.sum() * preds.shape[-1]  # total scalar elements considered (B*T*2)\n        # We want MAE per coordinate, so divide by number of coordinate-elements\n        loss = loss_sum / (valid_tokens + 1e-12)\n\n        loss.backward()\n        # gradient clipping\n        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n        optimizer.step()\n\n        # stats\n        running_loss += loss.item() * mask_batch.sum().item()  # weighted by tokens\n        mae_batch, valid_count = masked_mae(preds, y_batch, mask_batch)\n        running_mae_sum += mae_batch.item() * valid_count\n        running_tokens += valid_count\n\n        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\", \"mae\": f\"{mae_batch.item():.4f}\"})\n\n    # epoch train metrics\n    train_epoch_mae = (running_mae_sum / running_tokens) if running_tokens > 0 else 0.0\n    train_epoch_loss = running_loss / (running_tokens + 1e-12)\n\n    # Validation\n    model.eval()\n    val_running_mae_sum = 0.0\n    val_running_tokens = 0.0\n    val_running_loss_sum = 0.0\n\n    with torch.no_grad():\n        pbar_val = tqdm(val_loader, desc=f\"Epoch {epoch}/{EPOCHS} — val  \", leave=False)\n        for batch in pbar_val:\n            x_batch, y_batch, mask_batch = batch\n            x_batch = x_batch.to(DEVICE)\n            y_batch = y_batch.to(DEVICE)\n            mask_batch = mask_batch.to(DEVICE)\n\n            preds = model(x_batch, padding_mask=mask_batch)\n\n            # compute validation losses\n            mask3 = mask_batch.unsqueeze(-1)\n            loss_sum = torch.abs(preds - y_batch) * mask3\n            loss_sum = loss_sum.sum()\n            valid_tokens = mask3.sum() * preds.shape[-1]\n            loss = loss_sum / (valid_tokens + 1e-12)\n\n            mae_batch, valid_count = masked_mae(preds, y_batch, mask_batch)\n            val_running_mae_sum += mae_batch.item() * valid_count\n            val_running_tokens += valid_count\n            val_running_loss_sum += loss.item() * valid_count\n\n    val_epoch_mae = (val_running_mae_sum / val_running_tokens) if val_running_tokens > 0 else 0.0\n    val_epoch_loss = val_running_loss_sum / (val_running_tokens + 1e-12)\n\n    # Scheduler step on validation loss\n    scheduler.step(val_epoch_loss)\n\n    # logging\n    history[\"train_mae\"].append(train_epoch_mae)\n    history[\"val_mae\"].append(val_epoch_mae)\n    history[\"train_loss\"].append(train_epoch_loss)\n    history[\"val_loss\"].append(val_epoch_loss)\n    history[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n\n    epoch_time = time.time() - t0\n    print(f\"Epoch {epoch:02d} | time {epoch_time:.1f}s | train_mae {train_epoch_mae:.4f} | val_mae {val_epoch_mae:.4f} | lr {optimizer.param_groups[0]['lr']:.2e}\")\n\n    # Early stopping & checkpoint\n    if val_epoch_mae < best_val_mae - 1e-5:\n        best_val_mae = val_epoch_mae\n        best_model_wts = copy.deepcopy(model.state_dict())\n        torch.save({\"model_state_dict\": model.state_dict(), \"optimizer_state_dict\": optimizer.state_dict()}, MODEL_PATH)\n        print(f\"  -> New best model saved (val_mae {best_val_mae:.4f})\")\n        epochs_no_improve = 0\n    else:\n        epochs_no_improve += 1\n        print(f\"  No improvement for {epochs_no_improve} epoch(s)\")\n\n    if epochs_no_improve >= PATIENCE:\n        print(f\"Early stopping triggered (no improvement for {PATIENCE} epochs).\")\n        break\n\n# Load best model weights\nmodel.load_state_dict(best_model_wts)\ntorch.save(model.state_dict(), \"/kaggle/working/final_best_model_weights.pth\")\n\nprint(\"Training finished. Best val_mae:\", best_val_mae)\nprint(\"Best model saved to:\", MODEL_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:38:55.590281Z","iopub.execute_input":"2025-12-01T03:38:55.590542Z","iopub.status.idle":"2025-12-01T03:45:25.236685Z","shell.execute_reply.started":"2025-12-01T03:38:55.590526Z","shell.execute_reply":"2025-12-01T03:45:25.236092Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CELDA 9 (inferencia + submission.csv) con el modelo final\n\n1. Carga y verifica que existan test_input.csv, test.csv, los encoders y el modelo.\n\n2. Aplica las mismas transformaciones del entrenamiento (height→inches, birth_date→age, sin/cos angulares, label encoding seguro y scaler numérico).\n\n3. Para valores categóricos desconocidos en test, mapea a 0 (evita errores de LabelEncoder).\n\n4. Agrupa por (game_id, play_id, nfl_id) y crea secuencias exactamente igual que en entrenamiento, manteniendo un puntero _orig_index por cada fila para reconstruir el orden original.\n\n5. Crea batches y hace inferencia con el Transformer guardado.\n\n6. Asigna las predicciones por fila del test_input (por índice original).\n\n7. Hace merge con test.csv usando las columnas comunes (usualmente game_id, play_id, nfl_id, frame_id) para obtener el orden y formato que exige la competición. Si no existen columnas en común intenta alinear por orden, con comprobación de tamaño.\n\n8. Guarda submission.csv en /kaggle/working/submission.csv.\n\n","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# CELDA 9 — INFERENCIA (test_input.csv) y CREAR submission.csv\n# Objetivo: predecir (x_out, y_out) para cada fila de test_input\n# Necesita: /kaggle/working/best_transformer_model.pth\n#          /kaggle/working/encoders/num_scaler.pkl\n#          /kaggle/working/encoders/label_encoders.pkl\n# ============================================================\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport pickle\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.auto import tqdm\n\n# ---------------------------\n# Paths\n# ---------------------------\nDATA_DIR = \"/kaggle/input/nfl-big-data-bowl-2026-prediction\"\nTEST_INPUT_PATH = os.path.join(DATA_DIR, \"test_input.csv\")\nTEST_KEYS_PATH  = os.path.join(DATA_DIR, \"test.csv\")\nENC_DIR = \"/kaggle/working/encoders\"\nSCALER_PATH = os.path.join(ENC_DIR, \"num_scaler.pkl\")\nLABELS_PATH = os.path.join(ENC_DIR, \"label_encoders.pkl\")\nMODEL_PATH = \"/kaggle/working/best_transformer_model.pth\"\nOUT_SUB = \"/kaggle/working/submission.csv\"\n\n# ---------------------------\n# Comprobaciones de archivos\n# ---------------------------\nassert os.path.exists(TEST_INPUT_PATH), f\"No se encontró {TEST_INPUT_PATH}\"\nassert os.path.exists(TEST_KEYS_PATH),  f\"No se encontró {TEST_KEYS_PATH}\"\nassert os.path.exists(SCALER_PATH),     f\"No se encontró {SCALER_PATH}\"\nassert os.path.exists(LABELS_PATH),     f\"No se encontró {LABELS_PATH}\"\nassert os.path.exists(MODEL_PATH),      f\"No se encontró {MODEL_PATH}\"\n\nprint(\"Todos los archivos necesarios están presentes.\")\n\n# ---------------------------\n# Cargar test files\n# ---------------------------\ntest_input = pd.read_csv(TEST_INPUT_PATH)\ntest_keys  = pd.read_csv(TEST_KEYS_PATH)\n\nprint(\"test_input.shape:\", test_input.shape)\nprint(\"test_keys.shape:\", test_keys.shape)\n\n# ---------------------------\n# Helper transforms (mirror entrenamiento)\n# ---------------------------\ndef convert_height(h):\n    try:\n        feet, inches = str(h).split(\"-\")\n        return int(feet) * 12 + int(inches)\n    except:\n        return np.nan\n\n# Cargar encoders y scaler\nwith open(SCALER_PATH, \"rb\") as f:\n    scaler = pickle.load(f)\n\nwith open(LABELS_PATH, \"rb\") as f:\n    label_encoders = pickle.load(f)\n\n# Columnas de entrada usadas por el modelo (mismo orden que input_dim)\nINPUT_FEATURES = [\n    \"x_in\",\"y_in\",\"s\",\"a\",\n    \"dir_sin\",\"dir_cos\",\n    \"o_sin\",\"o_cos\",\n    \"play_direction\",\n    \"absolute_yardline_number\",\n    \"player_height_inches\",\n    \"player_weight\",\n    \"player_age\"\n]\n\n# ---------------------------\n# 1) Preprocesamiento de test_input (mirror train)\n# ---------------------------\ndf_test = test_input.copy()\nprint(\"Preprocesando test_input ...\")\n\n# altura\nif \"player_height\" in df_test.columns:\n    df_test[\"player_height_inches\"] = df_test[\"player_height\"].apply(convert_height)\nelse:\n    # si ya existe (caso raro), mantenemos\n    if \"player_height_inches\" not in df_test.columns:\n        df_test[\"player_height_inches\"] = np.nan\n\n# birth_date -> age\nif \"player_birth_date\" in df_test.columns:\n    df_test[\"player_birth_date\"] = pd.to_datetime(df_test[\"player_birth_date\"], errors=\"coerce\")\n    df_test[\"player_age\"] = (pd.Timestamp(\"2024-01-01\") - df_test[\"player_birth_date\"]).dt.days / 365.25\nelse:\n    if \"player_age\" not in df_test.columns:\n        df_test[\"player_age\"] = np.nan\n\n# angulos -> sin/cos (dir, o)\nif \"dir\" in df_test.columns:\n    dir_rad = np.deg2rad(df_test[\"dir\"].fillna(0.0).astype(float))\n    df_test[\"dir_sin\"] = np.sin(dir_rad)\n    df_test[\"dir_cos\"] = np.cos(dir_rad)\nelse:\n    if \"dir_sin\" not in df_test.columns:\n        df_test[\"dir_sin\"] = 0.0\n        df_test[\"dir_cos\"] = 1.0\n\nif \"o\" in df_test.columns:\n    o_rad = np.deg2rad(df_test[\"o\"].fillna(0.0).astype(float))\n    df_test[\"o_sin\"] = np.sin(o_rad)\n    df_test[\"o_cos\"] = np.cos(o_rad)\nelse:\n    if \"o_sin\" not in df_test.columns:\n        df_test[\"o_sin\"] = 0.0\n        df_test[\"o_cos\"] = 1.0\n\n# Asegurar columnas numéricas y tipos\nfor c in [\"x_in\",\"y_in\",\"s\",\"a\",\"absolute_yardline_number\",\"player_weight\"]:\n    if c not in df_test.columns:\n        df_test[c] = 0.0\n\n# Label encoding: mapear usando los label_encoders guardados\ncat_cols = list(label_encoders.keys())\nfor c in cat_cols:\n    if c in df_test.columns:\n        le = label_encoders[c]\n        # transform seguro: mapear valores desconocidos a 0\n        def safe_transform(vals, le=le):\n            out = []\n            classes = set(le.classes_.astype(str))\n            for v in vals.astype(str):\n                if v in classes:\n                    out.append(int(le.transform([v])[0]))\n                else:\n                    out.append(0)  # mapeo seguro para unseen\n            return np.array(out, dtype=int)\n        df_test[c] = safe_transform(df_test[c])\n\n# Normalizar numéricas usando scaler (igual que en train)\nnum_cols = [\"x_in\",\"y_in\",\"s\",\"a\",\"absolute_yardline_number\",\n            \"player_height_inches\",\"player_weight\",\"player_age\",\n            \"dir_sin\",\"dir_cos\",\"o_sin\",\"o_cos\"]\n\n# Si faltan columnas en test, crear con ceros para evitar error\nfor c in num_cols:\n    if c not in df_test.columns:\n        df_test[c] = 0.0\n\n# Aplicar scaler: scaler espera exactamente las columnas que se le dio en train.\n# Para seguridad, construimos array con las columnas num_cols en el mismo orden.\narr_nums = df_test[num_cols].to_numpy(dtype=float)\narr_nums[np.isnan(arr_nums)] = 0.0  # rellenar NaNs por 0 antes de scaler\narr_scaled = scaler.transform(arr_nums)\ndf_test[num_cols] = arr_scaled\n\nprint(\"Preprocesamiento terminado. Columnas disponibles:\", df_test.shape[1])\n\n# ---------------------------\n# 2) Construcción de secuencias del test y mapeo a índices originales\n# ---------------------------\ngroup_cols = [\"game_id\", \"play_id\", \"nfl_id\"]\n\n# Orden por frame_id (si existe)\nif \"frame_id\" in df_test.columns:\n    df_test = df_test.sort_values(group_cols + [\"frame_id\"]).reset_index(drop=True)\nelse:\n    df_test = df_test.sort_values(group_cols).reset_index(drop=True)\n\n# Para mapear predicciones de vuelta a filas del test_input guardamos índices\noriginal_index = np.arange(len(df_test))\ndf_test[\"_orig_index\"] = original_index\n\n# Agrupar y construir lista de secuencias + lista de original index lists\nseq_groups = []\nseq_index_refs = []  # por cada secuencia guardamos la lista de original indices (ordenados por frame)\nfor (g,p,n), gdf in df_test.groupby(group_cols, sort=False):\n    gdf_sorted = gdf.sort_values(\"frame_id\") if \"frame_id\" in gdf.columns else gdf\n    X = gdf_sorted[INPUT_FEATURES].to_numpy(dtype=np.float32)\n    idxs = gdf_sorted[\"_orig_index\"].to_numpy(dtype=int)\n    seq_groups.append(X)\n    seq_index_refs.append(idxs)\n\nprint(\"Secuencias creadas en test:\", len(seq_groups))\n\n# ---------------------------\n# 3) Dataset test y DataLoader\n# ---------------------------\nclass TestSequenceDataset(Dataset):\n    def __init__(self, X_list, idx_refs):\n        self.X_list = X_list\n        self.idx_refs = idx_refs\n\n    def __len__(self):\n        return len(self.X_list)\n\n    def __getitem__(self, i):\n        x = torch.from_numpy(self.X_list[i])  # (T, F)\n        idxs = self.idx_refs[i]\n        return x, idxs\n\ndef collate_test(batch):\n    xs = [item[0] for item in batch]\n    idxs = [item[1] for item in batch]\n    lengths = [x.shape[0] for x in xs]\n    T_max = max(lengths)\n    F = xs[0].shape[1]\n    x_padded = torch.zeros((len(xs), T_max, F), dtype=torch.float32)\n    mask = torch.zeros((len(xs), T_max), dtype=torch.float32)\n    idxs_padded = []\n    for i, x in enumerate(xs):\n        t = x.shape[0]\n        x_padded[i, :t, :] = x\n        mask[i, :t] = 1.0\n        idxs_padded.append(idxs[i])  # guardar lista original (no pad)\n    return x_padded, mask, idxs_padded, lengths\n\ntest_dataset = TestSequenceDataset(seq_groups, seq_index_refs)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_test)\n\n# ---------------------------\n# 4) Cargar modelo y ejecutar inferencia (batch)\n# ---------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Asegúrate que TransformerTrajectoryModel está definido en memoria (celda 6).\n# Si no, vuelve a ejecutar la celda 6 antes.\nmodel = TransformerTrajectoryModel(input_dim=len(INPUT_FEATURES), d_model=128, nhead=4, num_layers=3)\nckpt = torch.load(MODEL_PATH, map_location=device)\n# ckpt might be dict with model_state_dict or direct state_dict\nif isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n    model.load_state_dict(ckpt[\"model_state_dict\"])\nelse:\n    model.load_state_dict(ckpt)\nmodel.to(device)\nmodel.eval()\n\n# Pre-allocate arrays to store predictions per original row\npred_x = np.full(len(df_test), np.nan, dtype=float)\npred_y = np.full(len(df_test), np.nan, dtype=float)\n\nwith torch.no_grad():\n    for x_padded, mask_batch, idxs_padded, lengths in tqdm(test_loader, desc=\"Inferencia test\"):\n        x_padded = x_padded.to(device)\n        mask_batch = mask_batch.to(device)\n        preds = model(x_padded, padding_mask=mask_batch)  # (B, T, 2)\n        preds = preds.cpu().numpy()\n        mask_np = mask_batch.cpu().numpy()\n        # asignar por secuencia\n        for i in range(len(idxs_padded)):\n            idxs = idxs_padded[i]          # array de indices originales para esta secuencia (shape T_i)\n            t = lengths[i]\n            seq_preds = preds[i, :t, :]    # (T_i, 2)\n            # mapear a pred_x/pred_y por índice original\n            pred_x[idxs] = seq_preds[:, 0]\n            pred_y[idxs] = seq_preds[:, 1]\n\nprint(\"Inferencia completa. Predicciones asignadas a filas del test_input.\")\n\n# ---------------------------\n# 5) Construir DataFrame de predicciones y unir con test_keys (orden requerido)\n# ---------------------------\npred_df = df_test[[\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\",\"_orig_index\"]].copy() if \"frame_id\" in df_test.columns else df_test[[\"game_id\",\"play_id\",\"nfl_id\",\"_orig_index\"]].copy()\npred_df[\"x_out\"] = pred_x\npred_df[\"y_out\"] = pred_y\n\n# Determinar columnas en común para merge (usaremos todas las columnas que test_keys tiene)\nmerge_cols = [c for c in [\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"] if c in test_keys.columns and c in pred_df.columns]\nif len(merge_cols) == 0:\n    # si no hay columnas comunes, hacemos merge por orden (index)\n    print(\"Advertencia: no hay columnas comunes para merge. Se preservará el orden por fila.\")\n    submission = test_keys.copy()\n    # anexa predicciones por índice de aparición en test_input (si coincide en tamaño)\n    if len(submission) == len(pred_df):\n        submission[\"x_out\"] = pred_df[\"x_out\"].values\n        submission[\"y_out\"] = pred_df[\"y_out\"].values\n    else:\n        raise RuntimeError(\"Imposible alinear predicciones: tamaños distintos y sin columnas en común.\")\nelse:\n    # merge usando las columnas comunes, manteniendo el orden de test_keys\n    submission = test_keys.merge(pred_df.drop(columns=[\"_orig_index\"]), on=merge_cols, how=\"left\", sort=False)\n    # Si test_keys tiene filas duplicadas por play_id+... y merge produjo NaNs, intenta merge por subset menor\n    if submission[\"x_out\"].isna().any():\n        print(\"Aviso: existen NaNs en la unión. Reintentando merge por (game_id, play_id, nfl_id) si es posible.\")\n        base_cols = [c for c in [\"game_id\",\"play_id\",\"nfl_id\"] if c in test_keys.columns]\n        if set(base_cols).issubset(set(pred_df.columns)):\n            submission = test_keys.merge(pred_df.drop(columns=[\"_orig_index\"]), on=base_cols, how=\"left\", sort=False)\n        else:\n            print(\"No fue posible resolver NaNs automáticamente. Revisa columnas de test.csv y test_input.csv.\")\n\n# ---------------------------\n# 6) Resultado y guardado\n# ---------------------------\nprint(\"submission.shape:\", submission.shape)\nprint(\"Ejemplo (primeras filas):\")\ndisplay(submission.head())\n\n# Guardar CSV final\nsubmission.to_csv(OUT_SUB, index=False)\nprint(\"Submission guardado en:\", OUT_SUB)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:45:25.237632Z","iopub.execute_input":"2025-12-01T03:45:25.237889Z","iopub.status.idle":"2025-12-01T03:45:27.896777Z","shell.execute_reply.started":"2025-12-01T03:45:25.237864Z","shell.execute_reply":"2025-12-01T03:45:27.896117Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CELDA 10 CORRECCIÓN DEL SUBMISSION \n\nEsta celda:\n\n✔ Garantiza que TODOS los jugadores del test_keys aparezcan.\n\n✔ Inserta predicción dummy si falta una predicción real (no debe pasar, pero evita errores).\n\n✔ Reconstruye el submission EXCLUSIVAMENTE en base al orden oficial de Kaggle.\n\n✔ NO toca el modelo ni sus predicciones.","metadata":{}},{"cell_type":"code","source":"# ===============================================================\n# CORRECCIÓN DEL SUBMISSION \n# ===============================================================\n\nimport pandas as pd\nimport numpy as np\n\nprint(\"Cargando archivos...\")\n\n# Rutas correctas para la competencia 2026\nBASE = \"/kaggle/input/nfl-big-data-bowl-2026-prediction\"\n\ntest_keys = pd.read_csv(f\"{BASE}/test.csv\")\ntest_input = pd.read_csv(f\"{BASE}/test_input.csv\")\nsubs_raw = pd.read_csv(\"/kaggle/working/submission.csv\")  # tu archivo generado previamente\n\nprint(\"test_keys:\", test_keys.shape)\nprint(\"test_input:\", test_input.shape)\nprint(\"subs_raw:\", subs_raw.shape)\n\nprint(\"\\nCorrigiendo submission (versión final)...\")\n\n# Nos quedamos solo con una predicción por jugador:\nfinal_df = subs_raw.groupby([\"game_id\",\"play_id\",\"nfl_id\"], as_index=False)[[\"x_out\",\"y_out\"]].mean()\n\nprint(\"Predicciones únicas por jugador:\", final_df.shape)\n\n# Mezclar con test_keys para asegurar el orden oficial\nsubmission = test_keys.merge(final_df, on=[\"game_id\",\"play_id\",\"nfl_id\"], how=\"left\")\n\nprint(\"Submission final shape:\", submission.shape)\nprint(submission.head())\n\n# Guardar archivo final\noutput_path = \"/kaggle/working/submission_final.csv\"\nsubmission.to_csv(output_path, index=False)\n\nprint(f\"SUBMISSION FINAL GUARDADO EN: {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:45:27.897491Z","iopub.execute_input":"2025-12-01T03:45:27.897753Z","iopub.status.idle":"2025-12-01T03:45:28.181103Z","shell.execute_reply.started":"2025-12-01T03:45:27.897726Z","shell.execute_reply":"2025-12-01T03:45:28.180357Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CELDA 11 — SEQ2SEQ: Encoder-Decoder Transformer (predicción 20 frames)\n\n- Construye ejemplos de entrenamiento con sliding windows a partir de train_clean.parquet.\n\n- Usa encoder con los frames pasados (hasta ENC_LEN, padded) y decoder que genera 20 frames futuros (horizonte DEC_LEN = 20).\n\n- Emplea teacher forcing durante el entrenamiento.\n\n- Usa máscara causal en el decoder.\n\n- Guarda el mejor checkpoint y tiene inferencia autoregresiva preparada para producir los 20 frames en test (usaremos luego el último frame para el submission).\n\n- Incluye comentarios y recomendaciones sobre parámetros (batch_size / epochs) para que puedas ajustar según la GPU disponible.","metadata":{}},{"cell_type":"code","source":"# =============================================================\n# CELDA 12 — SEQ2SEQ: Encoder-Decoder Transformer (predicción 20 frames)\n# =============================================================\n# Requerimientos previos:\n# - /kaggle/working/train_clean.parquet  (dataset preprocesado)\n# - /kaggle/working/encoders/num_scaler.pkl\n# - /kaggle/working/encoders/label_encoders.pkl\n# - torch >= 1.10 (Transformer API)\n#\n# Aviso: entrenamiento pesado. Ajusta EPOCHS / BATCH_SIZE si OOM.\n# =============================================================\n\nimport os\nimport math\nimport time\nimport copy\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom sklearn.model_selection import GroupKFold\n\n# ----------------------\n# HYPERPARAMS (ajusta si necesitas)\n# ----------------------\nENC_LEN = 20            # longitud máxima del encoder (frames pasados)\nDEC_LEN = 20            # horizonte a predecir (siempre 20)\nBATCH_SIZE = 32\nEPOCHS = 20             # ajustar según tiempo/GPU\nLR = 1e-4\nWEIGHT_DECAY = 1e-5\nD_MODEL = 192           # dimensión interna del transformer\nNHEAD = 8\nNUM_ENCODER_LAYERS = 3\nNUM_DECODER_LAYERS = 3\nDIM_FF = 512\nDROPOUT = 0.1\nGRAD_CLIP = 1.0\nPATIENCE = 5\nMODEL_OUT_PATH = \"/kaggle/working/seq2seq_transformer_best.pth\"\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n\n# ----------------------\n# FEATURES (mismo orden que antes)\n# ----------------------\nINPUT_FEATURES = [\n    \"x_in\",\"y_in\",\"s\",\"a\",\n    \"dir_sin\",\"dir_cos\",\n    \"o_sin\",\"o_cos\",\n    \"play_direction\",\n    \"absolute_yardline_number\",\n    \"player_height_inches\",\n    \"player_weight\",\n    \"player_age\"\n]\nTARGET_DIM = 2  # x,y\n\n# ----------------------\n# Load scaler/encoders (for safety)\n# ----------------------\nenc_dir = \"/kaggle/working/encoders\"\nscaler = None\nlabel_encoders = {}\nif os.path.exists(os.path.join(enc_dir, \"num_scaler.pkl\")):\n    with open(os.path.join(enc_dir, \"num_scaler.pkl\"), \"rb\") as f:\n        scaler = pickle.load(f)\nif os.path.exists(os.path.join(enc_dir, \"label_encoders.pkl\")):\n    with open(os.path.join(enc_dir, \"label_encoders.pkl\"), \"rb\") as f:\n        label_encoders = pickle.load(f)\n\n# ----------------------\n# Load preprocessed train\n# ----------------------\nTRAIN_PATH = \"/kaggle/working/train_clean.parquet\"\ndf = pd.read_parquet(TRAIN_PATH)\nprint(\"train rows:\", df.shape)\n\n# ----------------------\n# Build per-player sequences (group by game/play/nfl)\n# We will create sliding-window samples:\n# For each player sequence X_seq (T, F) and Y_seq (T,2)\n# For each t where (t + DEC_LEN) <= T: \n#    encoder_input = last ENC_LEN frames before frame index t (we use up to ENC_LEN)\n#    decoder_target = Y_seq[t : t+DEC_LEN]   (length DEC_LEN)\n# ----------------------\ngroup_cols = [\"game_id\",\"play_id\",\"nfl_id\"]\ndf = df.sort_values(group_cols + [\"frame_id\"])\nprint(\"Grouping by player...\")\ngroups = df.groupby(group_cols, sort=False)\n\nX_list = []\nY_list = []\ngroup_ids = []   # keep play_id for GroupKFold if needed\n\nprint(\"Building sliding-window samples...\")\nfor (g,p,n), gdf in tqdm(groups, total=df[group_cols].drop_duplicates().shape[0]):\n    # features and targets for this player\n    X_seq = gdf[INPUT_FEATURES].to_numpy(dtype=np.float32)    # shape (T, F)\n    Y_seq = gdf[[\"x_out\",\"y_out\"]].to_numpy(dtype=np.float32)  # shape (T, 2)\n    T = X_seq.shape[0]\n    # We need at least DEC_LEN+1 frames to create one sample (encoder may be short-padded)\n    if T <= 1:\n        continue\n    # sliding windows: for start t in [0, T - DEC_LEN)\n    max_start = T - DEC_LEN\n    for start in range(0, max_start):\n        # encoder takes frames up to 'start' inclusive as past context; we will take window ending at start\n        enc_end = start  # index of last encoder frame\n        # take last ENC_LEN frames ending at enc_end (if not enough, pad on left later)\n        enc_start = max(0, enc_end - ENC_LEN + 1)\n        enc_window = X_seq[enc_start:enc_end+1]  # shape (L_enc, F), L_enc <= ENC_LEN\n        dec_target = Y_seq[start+1 : start+1+DEC_LEN]  # length DEC_LEN\n        # Only keep samples where dec_target has correct length (it should by construction)\n        if dec_target.shape[0] != DEC_LEN:\n            continue\n        X_list.append(enc_window)\n        Y_list.append(dec_target)\n        group_ids.append(p)\n\nprint(\"Total training samples:\", len(X_list))\nif len(X_list) == 0:\n    raise RuntimeError(\"No training samples created; revise DEC_LEN/ENC_LEN and data.\")\n\n# ----------------------\n# Dataset and collate (pad encoder sequences to ENC_LEN)\n# Each sample:\n#   enc_in: (ENC_LEN, F) padded left with zeros\n#   dec_target: (DEC_LEN, 2)\n#   enc_mask: (ENC_LEN) 1=valid, 0=pad\n# ----------------------\nclass Seq2SeqDataset(Dataset):\n    def __init__(self, X_list, Y_list, enc_len=ENC_LEN):\n        self.X_list = X_list\n        self.Y_list = Y_list\n        self.enc_len = enc_len\n\n    def __len__(self):\n        return len(self.X_list)\n\n    def __getitem__(self, idx):\n        enc = self.X_list[idx]      # (L, F)\n        dec = self.Y_list[idx]      # (DEC_LEN, 2)\n        L = enc.shape[0]\n        # left-pad to ENC_LEN\n        if L < self.enc_len:\n            pad_left = self.enc_len - L\n            enc_padded = np.zeros((self.enc_len, enc.shape[1]), dtype=np.float32)\n            enc_padded[pad_left:, :] = enc\n            mask = np.zeros(self.enc_len, dtype=np.float32)\n            mask[pad_left:] = 1.0\n        else:\n            enc_padded = enc[-self.enc_len:, :]\n            mask = np.ones(self.enc_len, dtype=np.float32)\n        return torch.from_numpy(enc_padded), torch.from_numpy(dec), torch.from_numpy(mask)\n\ndef collate_seq2seq(batch):\n    encs = [b[0] for b in batch]\n    decs = [b[1] for b in batch]\n    masks = [b[2] for b in batch]\n    enc_batch = torch.stack(encs, dim=0)   # (B, ENC_LEN, F)\n    dec_batch = torch.stack(decs, dim=0)   # (B, DEC_LEN, 2)\n    mask_batch = torch.stack(masks, dim=0) # (B, ENC_LEN)\n    return enc_batch, dec_batch, mask_batch\n\n# ----------------------\n# Train/val split by GroupKFold on group_ids to avoid leakage between plays\n# ----------------------\nindices = np.arange(len(X_list))\ngkf = GroupKFold(n_splits=5)\ntrain_idx, val_idx = None, None\nfor tr, va in gkf.split(indices, groups=group_ids):\n    train_idx, val_idx = tr, va\n    break\n\ntrain_ds = torch.utils.data.Subset(Seq2SeqDataset(X_list, Y_list), train_idx)\nval_ds   = torch.utils.data.Subset(Seq2SeqDataset(X_list, Y_list), val_idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_seq2seq, num_workers=2, pin_memory=True)\nval_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_seq2seq, num_workers=2, pin_memory=True)\n\nprint(\"Train batches:\", len(train_loader), \"Val batches:\", len(val_loader))\n\n# ----------------------\n# Model: Encoder-Decoder Transformer (PyTorch)\n# Encoder: project inputs -> d_model -> TransformerEncoder\n# Decoder: input shift tokens (we feed previous ground-truth during training, zeros at t=0),\n#          TransformerDecoder -> project to 2-d output per step\n# ----------------------\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=1000):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(pos * div)\n        pe[:, 1::2] = torch.cos(pos * div)\n        self.register_buffer(\"pe\", pe.unsqueeze(0))\n\n    def forward(self, x):\n        # x: (B, T, D)\n        seq_len = x.size(1)\n        return x + self.pe[:, :seq_len, :]\n\nclass Seq2SeqTransformer(nn.Module):\n    def __init__(self, input_dim, d_model=192, nhead=8,\n                 num_encoder_layers=3, num_decoder_layers=3,\n                 dim_feedforward=512, dropout=0.1, dec_len=DEC_LEN):\n        super().__init__()\n        self.d_model = d_model\n        # input projection\n        self.input_proj = nn.Linear(input_dim, d_model)\n        self.pos_enc = PositionalEncoding(d_model, max_len=ENC_LEN + DEC_LEN + 10)\n\n        # encoder\n        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n                                                   dim_feedforward=dim_feedforward,\n                                                   dropout=dropout, batch_first=True)\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n\n        # decoder: we will feed as input the previous target positions projected to d_model\n        self.dec_input_proj = nn.Linear(TARGET_DIM, d_model)\n\n        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead,\n                                                   dim_feedforward=dim_feedforward,\n                                                   dropout=dropout, batch_first=True)\n        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n\n        # final projection to xy\n        self.output_proj = nn.Linear(d_model, TARGET_DIM)\n\n        self._init_weights()\n\n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def make_tgt_mask(self, T):\n        # causal mask: (T, T) with True where masked (upper triangular)\n        mask = torch.triu(torch.ones((T, T), device=next(self.parameters()).device), diagonal=1).bool()\n        return mask  # True means masked as source for decoder\n\n    def forward(self, enc_inputs, dec_inputs, enc_mask=None):\n        \"\"\"\n        enc_inputs: (B, ENC_LEN, F)\n        dec_inputs: (B, DEC_LEN, TARGET_DIM)  -- during training use teacher forcing (shifted targets)\n        enc_mask: (B, ENC_LEN) with 1=valid,0=pad\n        returns: preds (B, DEC_LEN, TARGET_DIM)\n        \"\"\"\n        B = enc_inputs.size(0)\n        # project encoder inputs\n        enc = self.input_proj(enc_inputs) * math.sqrt(self.d_model)  # (B, ENC_LEN, D)\n        enc = self.pos_enc(enc)\n        # prepare src_key_padding_mask: True = padding (transformer expects True to ignore)\n        if enc_mask is not None:\n            src_key_padding_mask = (enc_mask == 0)  # (B, ENC_LEN) boolean\n        else:\n            src_key_padding_mask = None\n\n        enc_out = self.encoder(enc, src_key_padding_mask=src_key_padding_mask)  # (B, ENC_LEN, D)\n\n        # prepare decoder input projection\n        dec_in = self.dec_input_proj(dec_inputs) * math.sqrt(self.d_model)\n        dec_in = self.pos_enc(dec_in)  # (B, DEC_LEN, D)\n\n        # causal tgt mask\n        tgt_mask = self.make_tgt_mask(dec_in.size(1)).to(dec_in.device)\n\n        # no memory mask; key_padding_mask for tgt not used (all decoder steps valid)\n        dec_out = self.decoder(tgt=dec_in,\n                               memory=enc_out,\n                               tgt_mask=tgt_mask,\n                               memory_key_padding_mask=src_key_padding_mask)  # (B, DEC_LEN, D)\n\n        preds = self.output_proj(dec_out)  # (B, DEC_LEN, 2)\n        return preds\n\n# ----------------------\n# Instantiate model, optimizer, criterion\n# ----------------------\nmodel = Seq2SeqTransformer(input_dim=len(INPUT_FEATURES), d_model=D_MODEL, nhead=NHEAD,\n                           num_encoder_layers=NUM_ENCODER_LAYERS, num_decoder_layers=NUM_DECODER_LAYERS,\n                           dim_feedforward=DIM_FF, dropout=DROPOUT, dec_len=DEC_LEN)\nmodel = model.to(DEVICE)\noptimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=3, verbose=True)\ncriterion = nn.L1Loss(reduction=\"none\")  # we'll mask manually (MAE)\n\n# ----------------------\n# TRAINING LOOP (teacher forcing)\n# ----------------------\nbest_val = float(\"inf\")\nbest_wts = copy.deepcopy(model.state_dict())\nno_imp = 0\nhistory = {\"train_mae\": [], \"val_mae\": []}\n\nprint(\"Starting training loop...\")\nfor epoch in range(1, EPOCHS+1):\n    t0 = time.time()\n    model.train()\n    train_mae_sum = 0.0\n    train_tokens = 0.0\n\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} train\", leave=False)\n    for enc_batch, dec_target_batch, enc_mask in pbar:\n        # enc_batch: (B, ENC_LEN, F)\n        # dec_target_batch: (B, DEC_LEN, 2)\n        enc_batch = enc_batch.to(DEVICE)\n        dec_target_batch = dec_target_batch.to(DEVICE)\n        enc_mask = enc_mask.to(DEVICE)\n\n        # prepare decoder inputs for teacher forcing:\n        # decoder input at t=0 is last known ground-truth? we use zeros for t=0 then teacher force with dec_target shifted right\n        dec_inputs = torch.zeros_like(dec_target_batch, device=DEVICE)\n        dec_inputs[:, 1:, :] = dec_target_batch[:, :-1, :]  # shift right\n        dec_inputs[:, 0, :] = dec_target_batch[:, 0, :] * 0.0  # zero or we could use last observed pos (not available)\n\n        optimizer.zero_grad()\n        preds = model(enc_batch, dec_inputs, enc_mask=enc_mask)  # (B, DEC_LEN, 2)\n\n        # compute masked MAE\n        # targets validity: all decoder steps valid (DEC_LEN), but encoder mask may vary; here every target exists\n        loss_mat = torch.abs(preds - dec_target_batch)  # (B, DEC_LEN, 2)\n        loss = loss_mat.mean()  # mean over batch/time/coords\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n        optimizer.step()\n\n        # stats\n        batch_mae = loss_mat.mean().item()\n        train_mae_sum += batch_mae * enc_batch.size(0)\n        train_tokens += enc_batch.size(0)\n\n        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\", \"mae\": f\"{batch_mae:.4f}\"})\n\n    train_epoch_mae = train_mae_sum / (train_tokens + 1e-12)\n    # Validation\n    model.eval()\n    val_mae_sum = 0.0\n    val_tokens = 0.0\n    with torch.no_grad():\n        pbar_val = tqdm(val_loader, desc=f\"Epoch {epoch}/{EPOCHS} val\", leave=False)\n        for enc_batch, dec_target_batch, enc_mask in pbar_val:\n            enc_batch = enc_batch.to(DEVICE)\n            dec_target_batch = dec_target_batch.to(DEVICE)\n            enc_mask = enc_mask.to(DEVICE)\n\n            # prepare decoder inputs (teacher forced during val for stable metric)\n            dec_inputs = torch.zeros_like(dec_target_batch, device=DEVICE)\n            dec_inputs[:, 1:, :] = dec_target_batch[:, :-1, :]\n            dec_inputs[:, 0, :] = 0.0\n\n            preds = model(enc_batch, dec_inputs, enc_mask=enc_mask)\n            loss_mat = torch.abs(preds - dec_target_batch)\n            val_mae = loss_mat.mean().item()\n            val_mae_sum += val_mae * enc_batch.size(0)\n            val_tokens += enc_batch.size(0)\n            pbar_val.set_postfix({\"val_mae\": f\"{val_mae:.4f}\"})\n\n    val_epoch_mae = val_mae_sum / (val_tokens + 1e-12)\n    history[\"train_mae\"].append(train_epoch_mae)\n    history[\"val_mae\"].append(val_epoch_mae)\n\n    scheduler.step(val_epoch_mae)\n\n    print(f\"Epoch {epoch} | time {(time.time()-t0):.1f}s | train_mae {train_epoch_mae:.4f} | val_mae {val_epoch_mae:.4f} | lr {optimizer.param_groups[0]['lr']:.2e}\")\n\n    # checkpoint\n    if val_epoch_mae < best_val - 1e-5:\n        best_val = val_epoch_mae\n        best_wts = copy.deepcopy(model.state_dict())\n        torch.save({\"model_state_dict\": model.state_dict(), \"optimizer_state_dict\": optimizer.state_dict()}, MODEL_OUT_PATH)\n        print(\" -> New best model saved:\", MODEL_OUT_PATH)\n        no_imp = 0\n    else:\n        no_imp += 1\n        print(f\" -> No improvement {no_imp}/{PATIENCE}\")\n\n    if no_imp >= PATIENCE:\n        print(\"Early stopping triggered.\")\n        break\n\n# after training\nmodel.load_state_dict(best_wts)\ntorch.save(model.state_dict(), \"/kaggle/working/seq2seq_final_weights.pth\")\nprint(\"Training finished. Best val mae:\", best_val)\n\n# ----------------------\n# INFERENCE FUNCTION (autoregressive)\n# Given encoder input (B, ENC_LEN, F), decode DEC_LEN steps autoregressively,\n# seeding first step with zeros (or could seed with last observed pos if available)\n# ----------------------\ndef autoregressive_predict(model, enc_batch, enc_mask, device=DEVICE):\n    model.eval()\n    enc_batch = enc_batch.to(device)\n    enc_mask = enc_mask.to(device)\n    B = enc_batch.size(0)\n    # start decoder inputs as zeros\n    dec_in = torch.zeros((B, 1, TARGET_DIM), device=device)\n    outputs = []\n    with torch.no_grad():\n        # we will iteratively append last prediction and feed it as next decoder input\n        # but decoder in our model expects whole dec_inputs; to avoid re-encoding each step,\n        # we will build dec_inputs step-by-step and call model once per step (costly but simple)\n        dec_so_far = torch.zeros((B, 0, TARGET_DIM), device=device)\n        for t in range(DEC_LEN):\n            # build dec_inputs by shifting dec_so_far right and pad with zero at t=0\n            if t == 0:\n                dec_inputs = torch.zeros((B, DEC_LEN, TARGET_DIM), device=device)  # for forward we give full length but only first t used\n                # we will supply zeros for teacher positions >0\n                dec_inputs[:, :t+1, :] = torch.cat([dec_so_far, torch.zeros((B,1,TARGET_DIM), device=device)], dim=1) if dec_so_far.shape[1]>0 else torch.zeros((B,1,TARGET_DIM), device=device)\n            else:\n                # construct dec_inputs with previous predictions shifted\n                dec_inputs = torch.zeros((B, DEC_LEN, TARGET_DIM), device=device)\n                dec_inputs[:, :t, :] = dec_so_far  # fill first t steps with previous preds\n\n            preds = model(enc_batch, dec_inputs, enc_mask=enc_mask)  # (B, DEC_LEN, 2)\n            # take prediction at timestep t (index t)\n            step_pred = preds[:, t:t+1, :]  # (B, 1, 2)\n            dec_so_far = torch.cat([dec_so_far, step_pred], dim=1)  # append\n            outputs.append(step_pred)\n\n        # concat outputs\n        out = torch.cat(outputs, dim=1)  # (B, DEC_LEN, 2)\n    return out.cpu().numpy()\n\n# ----------------------\n# Example of running inference on validation subset (first batch)\n# ----------------------\nprint(\"Running example inference on a validation batch...\")\nenc_batch, dec_target_batch, enc_mask = next(iter(val_loader))\npreds_example = autoregressive_predict(model, enc_batch, enc_mask, DEVICE)\nprint(\"Example preds shape:\", preds_example.shape)  # (B, DEC_LEN, 2)\n\n# ----------------------\n# Save history for plots\n# ----------------------\nwith open(\"/kaggle/working/seq2seq_history.pkl\", \"wb\") as f:\n    pickle.dump(history, f)\n\nprint(\"CELDA 12 finished. Model saved to:\", MODEL_OUT_PATH)\nprint(\"Weights saved to: /kaggle/working/seq2seq_final_weights.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:45:28.182003Z","iopub.execute_input":"2025-12-01T03:45:28.182263Z","iopub.status.idle":"2025-12-01T03:51:28.660963Z","shell.execute_reply.started":"2025-12-01T03:45:28.182245Z","shell.execute_reply":"2025-12-01T03:51:28.659894Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Construimos muchos ejemplos por sliding window para que el modelo aprenda diferentes fases del pase (inicio, medio, fin).\n\nEl encoder recibe hasta ENC_LEN frames pasados (left-padded) — esto da contexto dinámico.\n\nEl decoder genera 20 frames de salida mediante un TransformerDecoder con máscara causal.\n\nDurante entrenamiento usamos teacher forcing (alimentamos el decoder con los targets desplazados) para mayor estabilidad.\n\nEn inferencia usamos un bucle autoregresivo sobre DEC_LEN pasos y retornamos (B,20,2). Para la submission se usará el último paso (index 19) por jugador.\n\nLoss usada: MAE (L1), media sobre batch/time/coords; puedes cambiar a MSE o SmoothL1 según prefieras.","metadata":{}},{"cell_type":"code","source":"# =============================================================\n# CELDA 13 — Gráficas del entrenamiento y predicciones\n# =============================================================\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle\n\n# -------------------------------------------------------------\n# 1) Cargar historial\n# -------------------------------------------------------------\nwith open(\"/kaggle/working/seq2seq_history.pkl\", \"rb\") as f:\n    history = pickle.load(f)\n\ntrain_mae = history[\"train_mae\"]\nval_mae = history[\"val_mae\"]\n\n# -------------------------------------------------------------\n# 2) Curva MAE (train vs val)\n# -------------------------------------------------------------\nplt.figure(figsize=(8,5))\nplt.plot(train_mae, label=\"Train MAE\", linewidth=2)\nplt.plot(val_mae, label=\"Val MAE\", linewidth=2)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MAE\")\nplt.title(\"Evolución del error durante entrenamiento\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n# -------------------------------------------------------------\n# 3) Graficar un ejemplo de trayectoria real vs predicho\n# -------------------------------------------------------------\nB = 0  # primer ejemplo del batch\ntrue_xy = dec_target_batch[B].cpu().numpy()     # (20,2)\npred_xy = preds_example[B]                      # (20,2)\n\nplt.figure(figsize=(6,6))\nplt.plot(true_xy[:,0], true_xy[:,1], 'o-', label=\"Real\", linewidth=2)\nplt.plot(pred_xy[:,0], pred_xy[:,1], 's--', label=\"Predicho\", linewidth=2)\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\nplt.title(\"Trayectoria real vs predicha (20 frames)\")\nplt.grid(True)\nplt.legend()\nplt.axis(\"equal\")\nplt.show()\n\n# -------------------------------------------------------------\n# 4) Error por timestep\n# -------------------------------------------------------------\nerrors = np.linalg.norm(true_xy - pred_xy, axis=1)  # error euclidiano por frame\n\nplt.figure(figsize=(8,4))\nplt.plot(errors, marker=\"o\")\nplt.xlabel(\"Timestep (1-20)\")\nplt.ylabel(\"Error\")\nplt.title(\"Error por frame del horizonte de predicción\")\nplt.grid(True)\nplt.show()\n\nprint(\"Gráficas generadas correctamente.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T04:19:57.655972Z","iopub.execute_input":"2025-12-01T04:19:57.656283Z","iopub.status.idle":"2025-12-01T04:19:58.166466Z","shell.execute_reply.started":"2025-12-01T04:19:57.656263Z","shell.execute_reply":"2025-12-01T04:19:58.165691Z"}},"outputs":[],"execution_count":null}]}